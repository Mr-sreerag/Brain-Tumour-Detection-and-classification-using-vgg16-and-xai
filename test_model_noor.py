# -*- coding: utf-8 -*-
"""Test model Noor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRpWyzzn6f3u5V7gtkzDSvtVLAeIOPMH
"""

# import drive
from google.colab import drive
drive.mount('/content/drive')

from keras.models import load_model
from keras.models import model_from_json
import numpy
import os

# load a model from drive
from tensorflow.keras.models import load_model
# Load the trained model
model = load_model('/content/drive/MyDrive/project msc/project msc.h5')

from keras.preprocessing.image import load_img, img_to_array
import numpy as np
import matplotlib.pyplot as plt

# Class labels
class_labels = ['glioma', 'notumor','pituitary', 'meningioma']

def detect_and_display(img_path, model, image_size=128):
    """
    Function to detect tumor and display results.
    If no tumor is detected, it displays "No Tumor".
    Otherwise, it shows the predicted tumor class and confidence.
    """
    try:
        # Load and preprocess the image
        img = load_img(img_path, target_size=(image_size, image_size))
        img_array = img_to_array(img) / 255.0  # Normalize pixel values
        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

        # Make a prediction
        predictions = model.predict(img_array)
        predicted_class_index = np.argmax(predictions, axis=1)[0]
        confidence_score = np.max(predictions, axis=1)[0]
          # Determine the class
        if class_labels[predicted_class_index] == 'notumor':
            result = "No Tumor"
        else:
            result = f"Tumor: {class_labels[predicted_class_index]}"

        # Display the image with the prediction
        plt.imshow(load_img(img_path))
        plt.axis('off')
        plt.title(f"{result} (Confidence: {confidence_score * 100:.2f}%)")
        plt.show()

    except Exception as e:
        print("Error processing the image:", str(e))

# Example usage
image_path = '/content/drive/MyDrive/project msc/braintumour noor/brin tumour noor/Training/meningioma/Tr-meTr_0007.jpg'  # Provide the path to your new image
detect_and_display(image_path, model)

# Example usage
image_path = '/content/drive/MyDrive/project msc/braintumour noor/brin tumour noor/Testing/pituitary/Te-pi_0027.jpg'  # Provide the path to your new image
detect_and_display(image_path, model)

# plot figure with explinable ai LIME

!pip install lime==0.2.0.1

import lime
from lime import lime_image
from skimage.segmentation import mark_boundaries
from skimage.segmentation import quickshift  # Import quickshift

# plot figure with explinable ai
!pip install lime
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import lime
from lime import lime_image

# Load the trained model
model = load_model('/content/drive/MyDrive/project msc/project msc.h5')

# Class labels
class_labels = ['pituitary', 'glioma', 'notumor', 'meningioma']

def explain_prediction(img_path, model, image_size=128):
    """
    Explains the model's prediction using LIME.
    """
    try:
        # Load and preprocess the image
        img = load_img(img_path, target_size=(image_size, image_size))
        img_array = img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Create a LIME explainer
        explainer = lime_image.LimeImageExplainer()


        # Explain the prediction
        explanation = explainer.explain_instance(
            image=img_array[0],
            classifier_fn=model.predict,
            top_labels=len(class_labels),
            hide_color=0,
            num_samples=1000,  # Increase for better accuracy, but slower performance
            segmentation_fn=quickshift
            # segmentation_fn=lambda x: quickshift(x, kernel_size=4, max_dist=200, ratio=0.2)
        )
  #**kernel_size:** Controls the size of the segments. Smaller values create finer segments.
  #**max_dist:** Maximum distance between pixels to be considered in the same segment.
  #**ratio:** Balances color-space proximity and image-space proximity. Lower values give more weight to color similarity.


        # Get the prediction
        predictions = model.predict(img_array)
        predicted_class_index = np.argmax(predictions, axis=1)[0]
        confidence_score = np.max(predictions, axis=1)[0]
        predicted_class = class_labels[predicted_class_index]

        # Display the original image
        plt.imshow(load_img(img_path))
        plt.axis('off')
        plt.title(f"Prediction: {predicted_class} (Confidence: {confidence_score * 100:.2f}%)")
        plt.show()


        # Display the explanation (positive contributions)
        temp, mask = explanation.get_image_and_mask(
            predicted_class_index,
            positive_only=True,
            num_features=8,  # Show top 5 contributing features
            hide_rest=True
        )
        plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))
        plt.title(f"Positive Contributions to {predicted_class} Prediction")
        plt.axis('off')
        plt.show()

        # Display the explanation (negative contributions)
        temp, mask = explanation.get_image_and_mask(
            predicted_class_index,
            positive_only=False,
            num_features=5,  # Show top 5 contributing features
            hide_rest=False
        )
        plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))
        plt.title(f"Negative Contributions to {predicted_class} Prediction")
        plt.axis('off')
        plt.show()

    except Exception as e:
        print("Error processing the image or explanation:", str(e))
from skimage.segmentation import mark_boundaries

image_path = '/content/drive/MyDrive/project msc/braintumour noor/brin tumour noor/Testing/meningioma/Te-me_0227.jpg'
explain_prediction(image_path, model)

image_path = '/content/drive/MyDrive/project msc/braintumour noor/brin tumour noor/Training/meningioma/Tr-meTr_0007.jpg'
explain_prediction(image_path, model)

import lime
from lime import lime_image
from skimage.segmentation import quickshift, mark_boundaries
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Load the trained model
model = load_model('/content/drive/MyDrive/project msc/project msc.h5')

# Class labels
class_labels = ['glioma', 'notumor', 'pituitary', 'meningioma']

# Medical knowledge dictionary (example)
medical_knowledge = {
    'glioma': {
        'features': ['irregular borders', 'heterogeneous intensity', 'mass effect'],
        'location': ['frontal lobe', 'temporal lobe', 'parietal lobe', 'occipital lobe', 'cerebellum', 'brainstem'],
        'description': 'Gliomas are aggressive tumors originating from glial cells.'
    },
    'meningioma': {
        'features': ['well-defined borders', 'homogeneous intensity', 'dural tail'],
        'location': ['cerebral convexities', 'parasagittal region', 'skull base'],
        'description': 'Meningiomas are typically benign tumors arising from the meninges.'
    },
    # ... (add knowledge for other tumor types) ...
}

def explain_prediction(img_path, model, medical_knowledge, image_size=128):
    """
    Explains the model's prediction using LIME and generates a written explanation.
    """
    try:
        # Load and preprocess the image
        img = load_img(img_path, target_size=(image_size, image_size))
        img_array = img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Create a LIME explainer
        explainer = lime_image.LimeImageExplainer()

        # Explain the prediction
        explanation = explainer.explain_instance(
            image=img_array[0],
            classifier_fn=model.predict,
            top_labels=len(class_labels),
            hide_color=0,
            num_samples=1000,
            segmentation_fn=quickshift
        )

        # Get the prediction
        predictions = model.predict(img_array)
        predicted_class_index = np.argmax(predictions, axis=1)[0]
        confidence_score = np.max(predictions, axis=1)[0]
        predicted_class = class_labels[predicted_class_index]

        # Display the original image with prediction
        plt.imshow(load_img(img_path))
        plt.axis('off')
        plt.title(f"Prediction: {predicted_class} (Confidence: {confidence_score * 100:.2f}%)")
        plt.show()

        # Display the LIME explanation (positive contributions)
        temp, mask = explanation.get_image_and_mask(
            predicted_class_index, positive_only=True, num_features=8, hide_rest=True
        )
        plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))
        plt.title(f"Positive Contributions to {predicted_class} Prediction")
        plt.axis('off')
        plt.show()

        # Generate written explanation
        explanation_text = f"The model predicts a high probability of {predicted_class} " \
                           f"(confidence: {confidence_score * 100:.2f}%) based on "

        # Extract relevant features from LIME explanation (example)
        # (You'll need to refine this based on your specific needs)
        top_features = explanation.as_list(label=predicted_class_index)
        feature_names = [feature[0] for feature in top_features]

        # Map features to medical knowledge
        tumor_knowledge = medical_knowledge.get(predicted_class, {})
        features_text = ', '.join(tumor_knowledge.get('features', []))
        location_text = ', '.join(tumor_knowledge.get('location', []))
        description_text = tumor_knowledge.get('description', '')

        explanation_text += f"the presence of {features_text} in the {location_text} region of the brain. "
        explanation_text += description_text

        print("Written Explanation:", explanation_text)

    except Exception as e:
        print("Error processing the image or explanation:", str(e))

# Example usage
image_path = '/content/drive/MyDrive/project msc/braintumour noor/brin tumour noor/Testing/meningioma/Te-me_0227.jpg'
explain_prediction(image_path, model, medical_knowledge)